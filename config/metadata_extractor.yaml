# llama-index에 제공할 metadata extractor 파라미터 설정 파일

metadata_extractor:
  # AI 모델 설정
  model:
    # 사용할 AI 모델 이름 (Fireworks AI 모델 또는 다른 LLM 제공자)
    name: "fireworks_ai/accounts/fireworks/models/gpt-oss-20b"
    
    # 생성할 최대 토큰 수 (긴 문서 처리 시 높게 설정)
    max_tokens: 10000
    
    # 창의성 조절 (0.0-1.0, 낮을수록 일관성 있는 결과)
    temperature: 0.1
    
    # 토큰 선택 범위 조절 (0.0-1.0, 높을수록 다양한 선택)
    top_p: 0.9
    
    # 스트리밍 응답 사용 여부 (실시간 결과 확인 가능)
    stream: false
