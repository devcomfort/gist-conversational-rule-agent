import logging
from typing import Iterator, Union, Any, Optional
import pystache
from llama_index.core import Document
from litellm import completion

from config.load_cleaner_config import load_cleaner_config, get_template_path

logger = logging.getLogger(__name__)


def refine_as_markdown(
    document: Union[Document, str],
    *,
    model: Optional[str] = None,
    max_tokens: Optional[int] = None,
    temperature: Optional[float] = None,
    top_p: Optional[float] = None,
    stream: Optional[bool] = None,
    **kwargs: Any,
) -> Iterator[str]:
    """ë¬¸ì„œë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ì •ì œí•©ë‹ˆë‹¤.

    AI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œì˜ ë‚´ìš©ì„ ì •ì œí•˜ê³  êµ¬ì¡°í™”í•˜ì—¬
    ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ê³„ì¸µì  í—¤ë” êµ¬ì¡°ë¥¼ ì ìš©í•˜ë©°,
    Hydra ì„¤ì •ê³¼ Mustache í…œí”Œë¦¿ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

    Args:
        document (Union[Document, str]): ì •ì œí•  ë¬¸ì„œ ë˜ëŠ” í…ìŠ¤íŠ¸ ë‚´ìš©
        model (str, optional): ì‚¬ìš©í•  AI ëª¨ë¸ (ì„¤ì •ê°’ ì˜¤ë²„ë¼ì´ë“œ)
        max_tokens (int, optional): ìµœëŒ€ í† í° ìˆ˜ (ì„¤ì •ê°’ ì˜¤ë²„ë¼ì´ë“œ)
        temperature (float, optional): ìƒì„± ì˜¨ë„ (ì„¤ì •ê°’ ì˜¤ë²„ë¼ì´ë“œ)
        top_p (float, optional): Top-p ìƒ˜í”Œë§ ê°’ (ì„¤ì •ê°’ ì˜¤ë²„ë¼ì´ë“œ)
        stream (bool, optional): ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ì—¬ë¶€ (ì„¤ì •ê°’ ì˜¤ë²„ë¼ì´ë“œ)
        **kwargs: litellm completionì— ì „ë‹¬í•  ì¶”ê°€ íŒŒë¼ë¯¸í„°

    Yields:
        str: ì •ì œëœ ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸ ì²­í¬ë“¤

    Raises:
        Exception: AI ëª¨ë¸ í˜¸ì¶œ ë˜ëŠ” ì‘ë‹µ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ ì‹œ

    Examples:
        >>> document = Document(text="ê³µì‹ ë¬¸ì„œ ë‚´ìš©...")
        >>> for chunk in refine_as_markdown(document):
        ...     print(chunk, end='', flush=True)

    Note:
        - Hydra ì„¤ì • íŒŒì¼ì—ì„œ ê¸°ë³¸ê°’ì„ ë¡œë“œí•˜ë©°, ë§¤ê°œë³€ìˆ˜ë¡œ ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥
        - Mustache í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ ë™ì ìœ¼ë¡œ ìƒì„±
        - ë¬¸ì„œ íƒ€ì…ê³¼ í˜•ì‹ì„ í…œí”Œë¦¿ ë³€ìˆ˜ë¡œ ì „ë‹¬í•˜ì—¬ ìœ ì—°í•œ ì²˜ë¦¬ ì§€ì›
    """
    # ì„¤ì • ë¡œë“œ
    cfg = load_cleaner_config()

    # ë§¤ê°œë³€ìˆ˜ ì„¤ì • (ì˜¤ë²„ë¼ì´ë“œ)
    model_name = model or cfg.cleaner.model.name
    max_tokens_val = max_tokens or cfg.cleaner.model.max_tokens
    temperature_val = temperature or cfg.cleaner.model.temperature
    top_p_val = top_p or cfg.cleaner.model.top_p
    stream_val = stream if stream is not None else cfg.cleaner.model.stream

    # ë¬¸ì„œ ë‚´ìš© ì¶”ì¶œ
    if isinstance(document, Document):
        content = document.get_content()
    else:
        content = str(document)

    # Mustache í…œí”Œë¦¿ ë¡œë“œ ë° ë Œë”ë§
    template_path = get_template_path(cfg.cleaner.templates.markdown_template)
    with open(template_path, "r", encoding="utf-8") as f:
        template = f.read()

    render_data = {"content": content}
    prompt = pystache.render(template, render_data)  # type: ignore[misc]

    try:
        logger.info(f"ë§ˆí¬ë‹¤ìš´ ì •ì œ ì‹œì‘ - ëª¨ë¸: {model_name}")

        response = completion(  # type: ignore
            model=model_name,
            messages=[{"role": "user", "content": prompt}],
            max_tokens=max_tokens_val,
            temperature=temperature_val,
            top_p=top_p_val,
            stream=stream_val,
            **kwargs,
        )

        if stream_val:
            logger.info("ìŠ¤íŠ¸ë¦¼ ì‘ë‹µ ìˆ˜ì‹  ì‹œì‘...")
            for chunk in response:
                if (
                    hasattr(chunk, "choices")
                    and chunk.choices
                    and len(chunk.choices) > 0
                ):
                    choice = chunk.choices[0]
                    if (
                        hasattr(choice, "delta")
                        and choice.delta
                        and hasattr(choice.delta, "content")
                    ):
                        content_chunk = choice.delta.content
                        if content_chunk:
                            yield content_chunk
        else:
            yield response.choices[0].message.content

    except Exception as e:
        logger.error(f"ë§ˆí¬ë‹¤ìš´ ì •ì œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise


def estimate_tokens(text: str) -> int:
    """í…ìŠ¤íŠ¸ì˜ ëŒ€ëµì ì¸ í† í° ìˆ˜ë¥¼ ì¶”ì •í•©ë‹ˆë‹¤."""
    # ê°„ë‹¨í•œ í† í° ì¶”ì •: ë‹¨ì–´ ìˆ˜ * 1.3 (í‰ê· ì ìœ¼ë¡œ 1ë‹¨ì–´ = 1.3í† í°)
    words = len(text.split())
    return int(words * 1.3)


if __name__ == "__main__":
    """ì§ì ‘ ì‹¤í–‰ ì‹œ ê°„ì´ í…ŒìŠ¤íŠ¸ ìˆ˜í–‰"""
    import time
    import os

    print("ğŸ“ Refine as Markdown - ê°„ì´ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # í…ŒìŠ¤íŠ¸ ë°ì´í„° (ìˆ˜ ì¤„ ìˆ˜ì¤€)
    test_document = """
    í”„ë¡œì íŠ¸ ê°œìš”
    ì´ í”„ë¡œì íŠ¸ëŠ” AI ê¸°ë°˜ ë¬¸ì„œ ì •ì œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. ë¬¸ì„œ ë‚´ìš© ë¶„ì„ ë° êµ¬ì¡°í™”
    2. ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    3. ê³„ì¸µì  í—¤ë” êµ¬ì¡° ì ìš©
    4. ë¶ˆí•„ìš”í•œ ë‚´ìš© ì œê±°
    
    ê¸°ìˆ  ìŠ¤íƒ:
    - Python 3.11+
    - Hydra ì„¤ì • ê´€ë¦¬
    - LiteLLM API ì—°ë™
    - Mustache í…œí”Œë¦¿ ì—”ì§„
    
    ì‚¬ìš© ë°©ë²•:
    í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ Document ê°ì²´ë‚˜ ë¬¸ìì—´ì„ ì…ë ¥í•˜ë©´
    ì •ì œëœ ë§ˆí¬ë‹¤ìš´ ê²°ê³¼ë¥¼ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    ì£¼ì˜ì‚¬í•­:
    API í‚¤ê°€ í•„ìš”í•˜ë©°, ëª¨ë¸ì— ë”°ë¼ ë¹„ìš©ì´ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """

    print("ğŸ“‚ ì…ë ¥ ë¬¸ì„œ:")
    print("-" * 40)
    print(test_document.strip())
    print("-" * 40)
    print(f"ğŸ“Š ì…ë ¥ í†µê³„:")
    print(f"   â€¢ ê¸€ì ìˆ˜: {len(test_document):,}")
    print(f"   â€¢ ë‹¨ì–´ ìˆ˜: {len(test_document.split()):,}")
    print(f"   â€¢ ë¼ì¸ ìˆ˜: {len(test_document.strip().split(chr(10))):,}")
    print(f"   â€¢ ì˜ˆìƒ í† í°: {estimate_tokens(test_document):,}")
    print()

    # API í‚¤ í™•ì¸
    api_key_available = bool(
        os.getenv("OPENAI_API_KEY")
        or os.getenv("ANTHROPIC_API_KEY")
        or os.getenv("FIREWORKS_API_KEY")
        or os.getenv("GROQ_API_KEY")
    )

    if not api_key_available:
        print("âš ï¸  API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ë‹¤ìŒ í™˜ê²½ë³€ìˆ˜ ì¤‘ í•˜ë‚˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”:")
        print("   - OPENAI_API_KEY")
        print("   - ANTHROPIC_API_KEY")
        print("   - FIREWORKS_API_KEY")
        print("   - GROQ_API_KEY")
        print()
        print("ğŸ”§ ì„¤ì • ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ë§Œ ìˆ˜í–‰í•©ë‹ˆë‹¤...")

        # ì„¤ì • ë¡œë“œ í…ŒìŠ¤íŠ¸
        try:
            cfg = load_cleaner_config()
            template_path = get_template_path(cfg.cleaner.templates.markdown_template)

            print(f"âœ… ì„¤ì • ë¡œë“œ ì„±ê³µ:")
            print(f"   â€¢ ëª¨ë¸: {cfg.cleaner.model.name}")
            print(f"   â€¢ ìµœëŒ€ í† í°: {cfg.cleaner.model.max_tokens:,}")
            print(f"   â€¢ Temperature: {cfg.cleaner.model.temperature}")
            print(f"   â€¢ í…œí”Œë¦¿ íŒŒì¼: {template_path}")
            print(f"   â€¢ í…œí”Œë¦¿ ì¡´ì¬: {'âœ…' if template_path.exists() else 'âŒ'}")

            if template_path.exists():
                with open(template_path, "r", encoding="utf-8") as f:
                    template_content = f.read()
                print(f"   â€¢ í…œí”Œë¦¿ ê¸¸ì´: {len(template_content)} ë¬¸ì")

        except Exception as e:
            print(f"âŒ ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")

        print("\nğŸ’¡ ì‹¤ì œ LLM í˜¸ì¶œì„ ìœ„í•´ì„œëŠ” API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”!")
        exit(0)

    print("ğŸš€ LLM í˜¸ì¶œ ì‹œì‘...")
    print()

    try:
        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        start_time = time.time()

        # ì •ì œ ì‹¤í–‰ (ìŠ¤íŠ¸ë¦¼ ëª¨ë“œ)
        print("ğŸ“„ ì •ì œëœ ê²°ê³¼:")
        print("=" * 60)

        result_chunks: list[str] = []
        for chunk in refine_as_markdown(test_document, stream=True):
            print(chunk, end="", flush=True)
            result_chunks.append(chunk)

        # ì™„ë£Œ ì‹œê°„ ê³„ì‚°
        end_time = time.time()
        elapsed_time = end_time - start_time

        # ê²°ê³¼ í†µê³„
        full_result = "".join(result_chunks)

        print("\n" + "=" * 60)
        print("ğŸ“Š ì²˜ë¦¬ ê²°ê³¼ í†µê³„:")
        print(f"   â€¢ ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
        print(f"   â€¢ ì¶œë ¥ ê¸€ì ìˆ˜: {len(full_result):,}")
        print(f"   â€¢ ì¶œë ¥ ë‹¨ì–´ ìˆ˜: {len(full_result.split()):,}")
        print(f"   â€¢ ì¶œë ¥ ë¼ì¸ ìˆ˜: {len(full_result.strip().split(chr(10))):,}")
        print(f"   â€¢ ì˜ˆìƒ ì¶œë ¥ í† í°: {estimate_tokens(full_result):,}")
        print(f"   â€¢ ì²˜ë¦¬ ì†ë„: {len(full_result) / elapsed_time:.1f} ë¬¸ì/ì´ˆ")

        # ì••ì¶•ë¥  ê³„ì‚°
        compression_ratio = len(full_result) / len(test_document)
        print(
            f"   â€¢ ì••ì¶•ë¥ : {compression_ratio:.2f}x ({'ì••ì¶•ë¨' if compression_ratio < 1 else 'í™•ì¥ë¨'})"
        )

        print()
        print("ğŸ‰ ë§ˆí¬ë‹¤ìš´ ì •ì œ ì™„ë£Œ!")

    except Exception as e:
        print(f"\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
        print(f"   {str(e)}")
        print()
        print("ğŸ’¡ ê°€ëŠ¥í•œ ì›ì¸:")
        print("   - API í‚¤ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŒ")
        print("   - ë„¤íŠ¸ì›Œí¬ ì—°ê²° ë¬¸ì œ")
        print("   - ëª¨ë¸ ì ‘ê·¼ ê¶Œí•œ ë¬¸ì œ")
        print("   - ì¼ì¼ ì‚¬ìš©ëŸ‰ ì´ˆê³¼")

        import traceback

        print(f"\nğŸ” ìƒì„¸ ì˜¤ë¥˜ ì •ë³´:")
        traceback.print_exc()
