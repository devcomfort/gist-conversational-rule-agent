"""
LiberVance RAG-X (í™•ì¥í˜• RAG) ì‹œìŠ¤í…œ

ì´ ëª¨ë“ˆì€ Excelê³¼ PDF íŒŒì¼ì„ ë™ì‹œì— ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” í™•ì¥ëœ RAG ì‹œìŠ¤í…œì…ë‹ˆë‹¤.
OpenAIì˜ ê³ ì„±ëŠ¥ o1 ëª¨ë¸ì„ í™œìš©í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°(Excel)ì™€ 
ë¹„êµ¬ì¡°í™”ëœ ë°ì´í„°(PDF)ë¥¼ í†µí•©ì ìœ¼ë¡œ ë¶„ì„í•˜ê³ , 
ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ìƒì„± ë° Excel ë‹¤ìš´ë¡œë“œ ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
- Excel íŒŒì¼ì„ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ë¡œ ìë™ ë³€í™˜
- PDF íŒŒì¼ì„ OpenAI Files APIë¡œ ì§ì ‘ ì²˜ë¦¬
- ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” ìë™ ì¶”ì¶œ ë° Excel ë³€í™˜
- ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ìš”ì²­ ìë™ ê°ì§€
- OpenAI o1 ëª¨ë¸ì„ í†µí•œ ê³ ê¸‰ ë¶„ì„
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ìµœì í™”

íŠ¹í™” ê¸°ëŠ¥:
- ë‹¤ì¤‘ ì‹œíŠ¸ Excel íŒŒì¼ ì§€ì›
- í…Œì´ë¸” í¬ê¸° ì œí•œ (ìµœëŒ€ 10,000í–‰ Ã— 10,000ì—´)
- ìë™ íŠ¹ìˆ˜ë¬¸ì ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
- ì‹¤ì‹œê°„ Excel íŒŒì¼ ìƒì„± ë° ë‹¤ìš´ë¡œë“œ
- JSON ë°ì´í„° ì¶”ì¶œ ë° ì²˜ë¦¬

ì‚¬ìš© ì‚¬ë¡€:
- ë¹„ì¦ˆë‹ˆìŠ¤ ë°ì´í„° ë¶„ì„ ë° ë³´ê³ ì„œ ìƒì„±
- ì¬ê³  ê´€ë¦¬ ë° ì˜ˆì¸¡ ë¶„ì„
- ì˜ˆì‚° ê³„íš ë° ë¦¬ì†ŒìŠ¤ í• ë‹¹
- ë°ì´í„° ì‹œê°í™”ë¥¼ ìœ„í•œ í…Œì´ë¸” ìƒì„±
- ë³µí•© ë¬¸ì„œ (Excel + PDF) í†µí•© ë¶„ì„
"""

import gradio as gr
import os, json, time, hashlib, threading
from collections import OrderedDict
from datetime import datetime
from dotenv import load_dotenv
# from gradio_excelupload_test import make_pdf
# from langchain_community.document_loaders import PyPDFLoader
from openai import OpenAI
import pandas as pd
import re
# import tiktoken

# Environment variables
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# Session variables
MAX_SESSIONS = 100
sessions = OrderedDict()
session_lock = threading.Lock()

# Model setup
MODEL = "o1"
CLIENT = OpenAI(api_key=OPENAI_API_KEY)

system_prompt = (
    "You are a helpful assistant that can answer questions based on the context when provided."
)


# --------- (A) SESSION SETUP ---------
def get_session_id(request: gr.Request):
    raw_id = request.client.host + str(request.headers.get("user-agent"))
    return hashlib.sha256(raw_id.encode()).hexdigest()

def init_session(session_id: str):
    sessions[session_id] = {
        "history": [{"role": "system", "content": system_prompt}],
        "files": [],
    }

# --------- (B) TABLE EXTRACTION ---------
def extract_tables_from_markdown(markdown_text):
    tables = []
    # í•˜ì´í”ˆ(-)ì„ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    table_pattern = r'\|(.+)\|[\r\n]\|([\s:\-]+\|)+'
    table_bodies = re.findall(r'\|(.+)\|[\r\n]\|([\s:\-]+\|)+[\r\n]((.*\|[\r\n])+)', markdown_text)

    for table_body in table_bodies:
        try:
            header_line = f"|{table_body[0]}|"
            separator_line = f"|{table_body[1]}"
            content_lines = table_body[2]

            headers = [cell.strip() for cell in header_line.split('|')[1:-1]]
            rows = []
            for line in content_lines.split('\n'):
                if '|' in line:
                    row_cells = [cell.strip() for cell in line.split('|')[1:-1]]
                    if row_cells:
                        rows.append(row_cells)

            if len(headers) > 0 and len(rows) > 0:
                max_cols = max(len(headers), max(len(row) for row in rows))
                padded_headers = headers + [''] * (max_cols - len(headers))
                padded_rows = [row + [''] * (max_cols - len(row)) for row in rows]

                df = pd.DataFrame(padded_rows, columns=padded_headers)
                tables.append(df)
        except Exception as e:
            print(f"í…Œì´ë¸” ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            continue

    return tables

# -----------------------------------------------------------------------------
# ì‘ë‹µì„ ì—‘ì…€ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
# -----------------------------------------------------------------------------
def convert_response_to_excel(bot_response: str, filename=None) -> tuple:
    dfs = extract_tables_from_markdown(bot_response)
    if not dfs:
        data = {"Content": [bot_response]}
        dfs = [pd.DataFrame(data)]
    if filename is None:
        ts = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"table_data_{ts}.xlsx"

    try:
        with pd.ExcelWriter(filename) as writer:
            for i, df in enumerate(dfs):
                sheet_name = f"Table_{i+1}" if i > 0 else "Data"
                df.to_excel(writer, sheet_name=sheet_name, index=False)
        return filename, "ì—‘ì…€ ì €ì¥ ì„±ê³µ"
    except Exception as e:
        return None, f"ì—‘ì…€ ë³€í™˜ ì˜¤ë¥˜: {str(e)}"

# -----------------------------------------------------------------------------
# í† í° ìˆ˜ ì œí•œ(ê°„ë‹¨ ì˜ˆì‹œ)
# -----------------------------------------------------------------------------
def trim_history(history, max_tokens=128000):
    # ë„ˆë¬´ ê¸¸ë©´ ìµœê·¼ 10ê°œë§Œ ìœ ì§€í•œë‹¤ëŠ” ì˜ˆì‹œ
    if len(history) > 10:
        return history[-10:]
    return history

# -----------------------------------------------------------------------------
# ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ìš”ì²­ ê°ì§€ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def detect_excel_download_request(text):
    """ì‚¬ìš©ì ì…ë ¥ì—ì„œ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ìš”ì²­ì„ ê°ì§€í•˜ëŠ” í•¨ìˆ˜"""
    patterns = [
        r'ì—‘ì…€ë¡œ\s*ë‹¤ìš´ë¡œë“œ',
        r'ì—‘ì…€\s*íŒŒì¼',
        r'excel\s*download',
        r'download\s*excel',
        r'ì—‘ì…€\s*ë‚´ë ¤ë°›',
        r'ì—‘ì…€\s*ì €ì¥',
        r'í‘œ\s*ë‹¤ìš´ë¡œë“œ',
        r'í‘œ\s*ì €ì¥',
        r'table\s*download',
        r'csv\s*ë‹¤ìš´ë¡œë“œ',
        r'xlsx',
        r'xls',
        r'ì—‘ì…€ë¡œ\s*ë³´ë‚´',
        r'ì—‘ì…€ë¡œ\s*ë³€í™˜'
    ]
    for pattern in patterns:
        if re.search(pattern, text, re.IGNORECASE):
            return True
    return False

# -----------------------------------------------------------------------------
# JSON ë°ì´í„° ì¶”ì¶œ í•¨ìˆ˜
# -----------------------------------------------------------------------------
def extract_json(text):
    try:
        # íŠ¹ì • ì½”ë“œ ë¸”ë¡(```) ì•ˆì—ì„œ JSON ì°¾ê¸° ë“± ì›í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ êµ¬í˜„
        # ì˜ˆì‹œëŠ” ë‹¨ìˆœí™”
        array_pattern = r'\[\s*{[\s\S]*?}\s*\]'
        matches = re.findall(array_pattern, text)
        if matches:
            for match in matches:
                try:
                    return json.loads(match)
                except json.JSONDecodeError:
                    continue
        return json.loads(text)  # ìµœí›„ì˜ ìˆ˜ë‹¨
    except json.JSONDecodeError as e:
        print(f"JSON ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None

# --------- (B) DOCUMENT TEXT EXTRACTION ---------
def excel_to_markdown(file_path, max_rows=10000, max_cols=10000):
    """
    ì—‘ì…€ íŒŒì¼ì„ ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
    
    Args:
        file_path: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        max_rows: ë³€í™˜í•  ìµœëŒ€ í–‰ ìˆ˜ (ê¸°ë³¸ê°’: 100)
        max_cols: ë³€í™˜í•  ìµœëŒ€ ì—´ ìˆ˜ (ê¸°ë³¸ê°’: 20)
    
    Returns:
        ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸” í˜•ì‹ì˜ ë¬¸ìì—´
    """
    try:
        # ì—‘ì…€ íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸ ì½ê¸°
        xl = pd.ExcelFile(file_path)
        sheet_names = xl.sheet_names
        
        result = []
        
        for sheet_name in sheet_names:
            # ê° ì‹œíŠ¸ë¥¼ DataFrameìœ¼ë¡œ ì½ê¸°
            df = pd.read_excel(file_path, sheet_name=sheet_name)
            
            # ë°ì´í„°í”„ë ˆì„ í¬ê¸° ì œí•œ
            if df.shape[0] > max_rows:
                df = df.iloc[:max_rows, :]
                
            if df.shape[1] > max_cols:
                df = df.iloc[:, :max_cols]
            
            # NaN ê°’ì„ ë¹ˆ ë¬¸ìì—´ë¡œ ë³€í™˜
            df = df.fillna('')
            
            # ì—´ ì´ë¦„ì— ìˆëŠ” íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬
            df.columns = [str(col).replace('|', '\\|').strip() for col in df.columns]
            
            # ë°ì´í„° ê°’ì— ìˆëŠ” íŠ¹ìˆ˜ ë¬¸ì ì²˜ë¦¬
            for col in df.columns:
                if df[col].dtype == 'object':
                    df[col] = df[col].astype(str).apply(lambda x: x.replace('|', '\\|').replace('\n', ' '))
            
            # í…Œì´ë¸” í—¤ë”ì™€ êµ¬ë¶„ì„  ìˆ˜ë™ ìƒì„±
            header = "| " + " | ".join(str(col) for col in df.columns) + " |"
            separator = "| " + " | ".join(["---"] * len(df.columns)) + " |"
            
            result.append(header)
            result.append(separator)
            
            # í…Œì´ë¸” ë‚´ìš© ìƒì„±
            for _, row in df.iterrows():
                row_values = [str(val) if len(str(val)) < 50 else str(val)[:47] + "..." for val in row]
                result.append("| " + " | ".join(row_values) + " |")
            
            # ì‹œíŠ¸ ì‚¬ì´ì— ë¹ˆ ì¤„ ì¶”ê°€
            if sheet_names.index(sheet_name) < len(sheet_names) - 1:
                result.append("\n")
        
        return "\n".join(result)
    
    except Exception as e:
        return f"ì—‘ì…€ íŒŒì¼ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

# --------- (C) PRIMARY CHAT FUNCTION ---------
def handle_query(user_query: str, user_pdfs: list, request: gr.Request):
    session_id = get_session_id(request)
    # Ensure session-safe access
    with session_lock:
        if session_id not in sessions:
            if len(sessions) >= MAX_SESSIONS:
                evicted_id, _ = sessions.popitem(last=False)
                print(f"ğŸ§¹ Removed LRU session: {evicted_id[:8]}...")
            init_session(session_id)
            print(f"âœ… New session created: {session_id[:8]}... | Total sessions: {len(sessions)}")
        session = sessions[session_id]
        sessions.move_to_end(session_id)

    history = session["history"]
    messages = history.copy()
    files = session["files"]
    start_time = time.time()                                                    # â±ï¸ TIMER

    # PDF/Excel íŒŒì¼ ì²˜ë¦¬
    if files:
        content = []
        for file in files:
            # PDF íŒŒì¼ì„ OpenAI APIì— ì—…ë¡œë“œ
            if file.name.endswith('.pdf'):
                try:
                    file_obj = CLIENT.files.create(
                        file=open(file.name, "rb"),
                        purpose="user_data"
                    )
                    content.append({
                        "type": "file",
                        "file": {"file_id": file_obj.id}})
                except Exception as e:
                    print(f"PDF ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            # Excel íŒŒì¼ì„ messagesì— ì¶”ê°€
            elif file.name.endswith('.xlsx' or '.xls'):
                try:
                    file_contents = excel_to_markdown(file.name)
                    messages.append({
                        "role": "user",
                        "content": f"ì—‘ì…€ ë‚´ìš© ({file.name}):\n{file_contents}"
                    })
                except Exception as e:
                    print(f"ì—‘ì…€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    # PDF + queryë¥¼ messagesì— ì¶”ê°€
    content.append({"type": "text", "text": user_query})
    messages.append({"role": "user", "content": content})

    try:
        completion = CLIENT.chat.completions.create(
            model=MODEL,
            messages=messages,
            max_completion_tokens=16384,
        )
        bot_response = completion.choices[0].message.content

        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ìš”ì²­ ì²˜ë¦¬
        excel_file = None
        if detect_excel_download_request(user_query):
            tables = extract_tables_from_markdown(bot_response)
            if tables:
                try:
                    ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                    excel_file = f"table_data_{ts}.xlsx"
                    with pd.ExcelWriter(excel_file) as writer:
                        for i, df in enumerate(tables):
                            sheet_name = f"Table_{i+1}" if i > 0 else "Data"
                            df.to_excel(writer, sheet_name=sheet_name, index=False)
                    bot_response += "\n\nâœ… ë§ˆí¬ë‹¤ìš´ í…Œì´ë¸”ì„ ì—‘ì…€ íŒŒì¼ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                except Exception as e:
                    bot_response += f"\n\nâŒ ì—‘ì…€ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            else:
                bot_response += "\n\nâ“ ë³€í™˜í•  í…Œì´ë¸”ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. í…Œì´ë¸” í˜•ì‹ì˜ ë°ì´í„°ë¥¼ ìš”ì²­í•´ ì£¼ì„¸ìš”."
        
        # ëŒ€í™” ê¸°ë¡ ì €ì¥
        history.append({"role": "user", "content": user_query})
        history.append({"role": "assistant", "content": bot_response})
        save_history(history, session_id)
   
        end_time = time.time()                                                      # â±ï¸ TIMER
        elapsed_time = end_time - start_time                                        # â±ï¸ TIMER
        print(f"Responded to user query in {elapsed_time:.2f} seconds")             # â±ï¸ TIMER
        return history, gr.update(value=excel_file, visible=excel_file is not None)

    except Exception as e:
        error_message = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        print(error_message)  # ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥
        
        # ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ê°€
        history.append({"role": "user", "content": user_query})
        history.append({"role": "assistant", "content": error_message})
        
        return history, gr.update(value=None, visible=False)

# --------- (D) ADDITIONAL FUNCTIONS ---------
def save_history(history, session_id):
    """ëŒ€í™” ê¸°ë¡(history)ì„ JSON íŒŒì¼ë¡œ ì €ì¥"""
    folder = "./chat_logs_lvragx"
    os.makedirs(folder, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d")
    filename = os.path.join(folder, f"{timestamp}_{session_id}.json")
    counter = 1
    while os.path.exists(filename):
        filename = os.path.join(folder, f"{timestamp}_{session_id}_{counter}.json")
        counter += 1
    with open(filename, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

def reset_session(request: gr.Request):
    """ëŒ€í™” ë° íŒŒì¼ ì—…ë¡œë“œ ë‚´ì—­ ì‚­ì œ"""
    session_id = get_session_id(request)
    with session_lock:
        init_session(session_id)
        sessions.move_to_end(session_id)
        print(f"â™»ï¸ Session {session_id[:8]}... reset.")
    return "", []


# # --------- (E) Gradio UI ---------
# css = """
# div {
#     flex-wrap: nowrap !important;
# }
# .responsive-height {
#     height: 768px !important;
#     padding-bottom: 64px !important;
# }
# .fill-height {
#     height: 100% !important;
#     flex-wrap: nowrap !important;
# }
# .extend-height {
#     min-height: 260px !important;
#     flex: 1 !important;
#     overflow: auto !important;
# }
# footer {
#     display: none !important;
# }
# """

# with gr.Blocks(title="LiberVance RAG-X", css=css, fill_height=True) as demo:
#     gr.Markdown("<center><h1>ğŸ“ˆ LiberVance RAG-X</h1></center>")
#     with gr.Row(elem_classes=["responsive-height"]):
#         # Input column
#         with gr.Column(elem_classes=["fill-height"]):
#             chatbot = gr.Chatbot(elem_classes=["extend-height"], type="messages")
#             file_download = gr.File(label="Download file", visible=False, elem_classes=["extend-height"])
#         # Output column
#         with gr.Column(elem_classes=["fill-height"]):
#             file_upload = gr.Files(label="Upload file(s) (PDF or Excel)", file_types=[".pdf", ".xlsx"], elem_classes=["extend-height"])
#             user_input = gr.Textbox(label="Enter your query here", placeholder=(
#                 "e.g.,\n"
#                 "1. Show the table of contents, data summary, or specific sheet/table from the uploaded files.\n"
#                 "2. Identify when a key metric (e.g., inventory level, budget, or capacity) will reach a threshold or run out.\n"
#                 "3. Recommend an action or timeline (e.g., reorder date, resource allocation, deadline) based on trends in the data."
#             ), lines=8)
#             with gr.Row():
#                 send_btn = gr.Button("Submit", variant="primary")
#                 reset_btn = gr.Button("Clear", variant="secondary", elem_classes="clear-btn")
#     # Event listeners
#     user_input.submit(handle_query, inputs=[user_input, file_upload], 
#                       outputs=[chatbot, file_download])
#     send_btn.click(handle_query, inputs=[user_input, file_upload], 
#                    outputs=[chatbot, file_download])
#     reset_btn.click(reset_session, inputs=[], outputs=[user_input, chatbot])

# demo.launch(share=True, favicon_path="")